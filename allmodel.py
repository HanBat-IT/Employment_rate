import pandas as pd
import numpy as np
import os
from glob import glob
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import matplotlib.font_manager as fm

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

folder_path = "ì·¨ì—…ë¥ ì˜ˆì¸¡"
file_paths = glob(os.path.join(folder_path, "*.xlsx"))
df_list = [pd.read_excel(fp, sheet_name=None, engine='openpyxl') for fp in file_paths]
df = pd.concat([sheet for file in df_list for sheet in file.values()], ignore_index=True)

df = df.dropna(subset=['ëŒ€í•™êµëª…', 'í•™ê³¼ëª…', 'ëª¨ì§‘ì¸ì›', 'í‰ê· ì…í•™ë“±ê¸‰', 'ì·¨ì—…ë¥ '])

df['ëŒ€í•™êµëª…'] = df['ëŒ€í•™êµëª…'].replace('êµ­ë¦½í•œë°­ëŒ€í•™êµ', 'HëŒ€í•™êµ')
unique_univs = df['ëŒ€í•™êµëª…'].unique()
anon_map = {univ: f"{chr(65+i)}ëŒ€í•™êµ" for i, univ in enumerate(unique_univs) if univ != 'HëŒ€í•™êµ'}
df['ëŒ€í•™êµëª…'] = df['ëŒ€í•™êµëª…'].replace(anon_map)

X = df[['ëŒ€í•™êµëª…', 'í•™ê³¼ëª…', 'ëª¨ì§‘ì¸ì›', 'í‰ê· ì…í•™ë“±ê¸‰']]
y = df['ì·¨ì—…ë¥ ']

categorical = ['ëŒ€í•™êµëª…', 'í•™ê³¼ëª…']
numeric = ['ëª¨ì§‘ì¸ì›', 'í‰ê· ì…í•™ë“±ê¸‰']

dept_categories = sorted(df['í•™ê³¼ëª…'].astype(str).unique().tolist())
univ_categories = sorted(df['ëŒ€í•™êµëª…'].astype(str).unique().tolist())

if 'ì‚°ì—…ê²½ì˜ê³µí•™ê³¼' in dept_categories:
    dept_categories.remove('ì‚°ì—…ê²½ì˜ê³µí•™ê³¼')
    dept_categories = ['ì‚°ì—…ê²½ì˜ê³µí•™ê³¼'] + dept_categories
if 'HëŒ€í•™êµ' in univ_categories:
    univ_categories.remove('HëŒ€í•™êµ')
    univ_categories = ['HëŒ€í•™êµ'] + univ_categories

onehot_encoder = OneHotEncoder(categories=[univ_categories, dept_categories], drop='first', handle_unknown='ignore')
preprocessor = ColumnTransformer([
    ('cat', onehot_encoder, categorical),
    ('num', StandardScaler(), numeric)
])

models = {
    "LinearRegression": (LinearRegression(), {}),
    "RandomForest": (RandomForestRegressor(random_state=42), {
        'regressor__n_estimators': [100],
        'regressor__max_depth': [5, 10, None]
    }),
    "XGBoost": (XGBRegressor(objective='reg:squarederror', random_state=42), {
        'regressor__n_estimators': [100],
        'regressor__max_depth': [3, 5],
        'regressor__learning_rate': [0.05, 0.1]
    }),
    "LightGBM": (LGBMRegressor(random_state=42), {
        'regressor__n_estimators': [100],
        'regressor__num_leaves': [31, 50],
        'regressor__learning_rate': [0.05, 0.1]
    })
}

hanbat_df = df[df['ëŒ€í•™êµëª…'] == 'HëŒ€í•™êµ']

for name, (regressor, param_grid) in models.items():
    print(f"\n===== ğŸ” ëª¨ë¸: {name} =====")
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', regressor)
    ])

    if param_grid:
        grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)
        grid.fit(X, y)
        model = grid.best_estimator_
        best_params = grid.best_params_
    else:
        pipeline.fit(X, y)
        model = pipeline
        best_params = {}

    y_pred_all = model.predict(X)
    df_result = df.copy()
    df_result['ì˜ˆì¸¡ ì·¨ì—…ë¥ '] = y_pred_all
    df_result['ì˜ˆì¸¡ ì˜¤ì°¨'] = df_result['ì˜ˆì¸¡ ì·¨ì—…ë¥ '] - df_result['ì·¨ì—…ë¥ ']
    hanbat_result = df_result[df_result['ëŒ€í•™êµëª…'] == 'HëŒ€í•™êµ']

    r2 = r2_score(hanbat_result['ì·¨ì—…ë¥ '], hanbat_result['ì˜ˆì¸¡ ì·¨ì—…ë¥ '])
    mae = mean_absolute_error(hanbat_result['ì·¨ì—…ë¥ '], hanbat_result['ì˜ˆì¸¡ ì·¨ì—…ë¥ '])
    rmse = np.sqrt(mean_squared_error(hanbat_result['ì·¨ì—…ë¥ '], hanbat_result['ì˜ˆì¸¡ ì·¨ì—…ë¥ ']))

    print("â–¶ í•œë°­ëŒ€ ì˜ˆì¸¡ RÂ²:", r2)
    print("â–¶ MAE:", mae)
    print("â–¶ RMSE:", rmse)
    print("â–¶ Best Params:", best_params)

    cv_metrics = ['r2', 'neg_mean_absolute_error', 'neg_root_mean_squared_error']
    cv_results = cross_validate(model, X, y, cv=5, scoring=cv_metrics)
    r2_scores = cv_results['test_r2']
    mae_scores = -cv_results['test_neg_mean_absolute_error']
    rmse_scores = -cv_results['test_neg_root_mean_squared_error']

    print("â–¶ 5-Fold í‰ê·  RÂ²:", np.mean(r2_scores))
    print("â–¶ 5-Fold í‰ê·  MAE:", np.mean(mae_scores))
    print("â–¶ 5-Fold í‰ê·  RMSE:", np.mean(rmse_scores))

    output_dir = os.path.join(folder_path, f"{name}_HëŒ€í•™êµ_ì˜ˆì¸¡ê²°ê³¼")
    os.makedirs(output_dir, exist_ok=True)

    hanbat_result.to_csv(os.path.join(output_dir, "ì˜ˆì¸¡ê²°ê³¼.csv"), index=False, encoding='utf-8-sig')

    cv_df = pd.DataFrame({
        'Fold': [f"Fold{i+1}" for i in range(5)],
        'RÂ²': r2_scores,
        'MAE': mae_scores,
        'RMSE': rmse_scores
    })
    cv_df.loc['í‰ê· '] = cv_df.mean(numeric_only=True)
    cv_df.loc['í‘œì¤€í¸ì°¨'] = cv_df.std(numeric_only=True)
    cv_df.to_csv(os.path.join(output_dir, "CV_5Fold_ì „ì²´ì§€í‘œ.csv"), index=True, encoding='utf-8-sig')

    if hasattr(model.named_steps['regressor'], 'feature_importances_'):
        importances = model.named_steps['regressor'].feature_importances_
    else:
        importances = model.named_steps['regressor'].coef_

    feature_names_cat = model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical)
    feature_names_all = np.concatenate([feature_names_cat, numeric])

    importance_col = 'Importance' if name != "LinearRegression" else 'Coefficient'
    importance_df = pd.DataFrame({
        'Feature': feature_names_all,
        importance_col: importances
    }).sort_values(by=importance_col, key=np.abs, ascending=False)

    importance_df.to_csv(os.path.join(output_dir, "ë³€ìˆ˜ì¤‘ìš”ë„.csv"), index=False, encoding='utf-8-sig')

    if name == "LinearRegression":
        print("\n íšŒê·€ê³„ìˆ˜ ìƒìœ„ ë³€ìˆ˜:")
        print(importance_df.head(10))
        importance_df.to_csv(os.path.join(output_dir, "íšŒê·€ê³„ìˆ˜_í•´ì„.csv"), index=False, encoding='utf-8-sig')

    plt.figure(figsize=(10, 6))
    plt.barh(importance_df['Feature'][:20][::-1], importance_df[importance_col][:20][::-1])
    plt.xlabel("ì¤‘ìš”ë„" if name != "LinearRegression" else "ê³„ìˆ˜ í¬ê¸°")
    plt.title(f"{name} ìƒìœ„ 20ê°œ ë³€ìˆ˜ ì¤‘ìš”ë„")
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "ë³€ìˆ˜ì¤‘ìš”ë„_ì‹œê°í™”.png"))
    plt.close()

plt.figure(figsize=(14, 6))
sns.boxplot(x='í•™ê³¼ëª…', y='ì·¨ì—…ë¥ ', data=df)
plt.xticks(rotation=90)
plt.title("í•™ê³¼ë³„ ì·¨ì—…ë¥  ë¶„í¬ (ì°¨ì´ ê°•ì¡°)")
plt.tight_layout()
plt.savefig(os.path.join(folder_path, "í•™ê³¼ë³„_ì·¨ì—…ë¥ _ë¶„í¬.png"))
plt.close()
